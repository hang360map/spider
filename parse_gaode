#!/home/zhuhang-xy/python/bin/python10
#coding=utf-8
import urllib2
import sys
reload(sys)
import string
from bs4 import BeautifulSoup
import re
import json

INPUT_FILE = "cityid2name.dict"
EXCEPTION_FILE = "exception_city"
exception_file = open(EXCEPTION_FILE, 'w')

def gaode_business():
    input = open(INPUT_FILE, 'r')
    for line in input:
        cityid = line.strip().strip('\n').split('\t')[0].strip()
        if cityid != "":
            parse_gaode(line.strip().strip('\n').split('\t'))
        print line.strip().strip('\n').split('\t')[1]
    input.close()
    exception_file.close()
    
def parse_gaode(city_info):
    try:
        url_string = "http://ditu.amap.com/service/poiInfo?query_type=TQUERY&city=" + city_info[0].strip() + "&keywords=%E7%BE%8E%E9%A3%9F&pagesize=20"
        url = urllib2.urlopen(url_string).read()
        url_json = json.loads(url)
        soup = BeautifulSoup(url_json["html"])
        place_set = soup.find(attrs={'class', 'classify-area'})

        region = []
        place_area_level = place_set.find(attrs={'class','classify-area-level1'})
        p = re.compile('<li.*><span.*>(.*)</spa.*><span.*')
        size = len(place_area_level.findAll('li'))
        if size < 2:
            return
        output_name = city_info[0].strip() + "_" + city_info[1].strip()
        output = open(output_name, 'w')
        for i in range(1, size):
            m = p.match((str)(place_area_level.findAll('li')[i]))
            region.append(m.group(1))

        place = place_set.findAll('ul')
        p = re.compile('<li.*>(.*)</li>')
        for i in range(3, len(place)):
            tmp_places = place[i].findAll('li')
            places = ""
            for j in range(1, len(tmp_places)):
                m = p.match((str)(tmp_places[j]))
                places = places + m.group(1) + "\t"
            output.write(region[i - 3] + ":" + places + "\n")
        output.close()
    except Exception:
        exception_file.write(city_info[0] + "\t" + city_info[1] + "\n")
        
